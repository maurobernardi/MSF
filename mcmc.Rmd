---
title: "Bayesian Inference via Markov Chain Monte Carlo (MCMC)"
author: "Mauro Bernardi"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  rmarkdown::github_document:
    number_sections: true
---



# License

This work is licensed under a Creative Commons
Attribution-ShareAlike 4.0 International License
(http://creativecommons.org/licenses/by-sa/4.0/).

# R

 * The version of R used to make this document is `r getRversion()`.

 * The version of the `rmarkdown` package used to make this document is
   `r packageVersion("rmarkdown")`.

 * The version of the `knitr` package used to make this document is
   `r packageVersion("knitr")`.

 * The version of the `mcmc` package used to make this document is
   `r packageVersion("mcmc")`.

 * The version of the `KernSmooth` package used to make this document is
   `r packageVersion("KernSmooth")`.

```{r}
library("mcmc")
library("KernSmooth")
```

# History

## Bayes

Thomas Bayes ([Wikipedia article](https://en.wikipedia.org/wiki/Thomas_Bayes))
died in 1761 by which time he had written an unpublished note about the
binomial distribution and what would now be called Bayesian inference for
it using a flat prior.  The note was found by a friend and read to the Royal
Society of London in 1763 and published in its *Philosophical Transactions*
in 1764 thus becoming widely known.

Bayesian inference was the first form of statistical inference to be developed.
The book <em>Essai philosophique sur les probabilitÃ©s</em>
([Laplace, 1814)](https://en.wikipedia.org/wiki/Pierre-Simon_Laplace#Analytic_theory_of_probabilities), which was a major landmark in probability and statistics
covering all of the probability and statistics of its day, was Bayesian
in orientation.  When the [method of least
squares](https://en.wikipedia.org/wiki/Least_squares) was independently
invented by Legendre and Gauss, it was given a justification by Gauss
that we would now express as saying that least squares is maximum likelihood
under the "usual" assumption of
[homoscedastic](https://en.wikipedia.org/wiki/Homoscedasticity) normal errors,
but this modern explanation is seriously anachronistic.  The notion
of maximum likelihood is a twentieth century notion,
[invented by R. A. Fisher in 1912 and given its fundamental theory by him
in 1922](https://projecteuclid.org/euclid.ss/1030037906).
What Gauss actually gave was the analogous Bayesian argument that the
least squares estimate is the posterior mode assuming flat priors
(if this doesn't make sense it is explained below).
This connection between least squares and the normal distribution is
why the normal distribution is often called the *Gaussian distribution*,
despite its discovery (as the limit in the central limit theorem)
by [de Moivre in 1738](https://en.wikipedia.org/wiki/De_Moivre%E2%80%93Laplace_theorem).

Bayesianism, then called "inverse probability",
went into a century-long decline (the Bayesian "dark ages")
after severe criticism of the method
by the logicians Boole and Venn followed by the invention of so-called
"frequentist" statistics
in the twentieth century by
[Karl Pearson](https://en.wikipedia.org/wiki/Karl_Pearson),
[W. S. Gosset](https://en.wikipedia.org/wiki/William_Sealy_Gosset),
[R. A. Fisher](https://en.wikipedia.org/wiki/Ronald_Fisher),
[E. S. Pearson](https://en.wikipedia.org/wiki/Egon_Pearson),
[Jerzy Neyman](https://en.wikipedia.org/wiki/Jerzy_Neyman),
[Abraham Wald](https://en.wikipedia.org/wiki/Abraham_Wald),
and many others.  The term "frequentist" statistics is
totally misleading because this theory has
nothing whatsoever to do with so-called [frequentist interpretation of
probability](https://en.wikipedia.org/wiki/Frequentist_probability),
although many people, mislead by the names, think there must be
some connection.  It should be called *samplingdistributionist*
if English made words that way, because, of course, it is statistics
based on sampling distributions.
[More on this below](#bayesians-versus-frequentists).

Bayesianism was resuscitated as philosophy by
[B. de Finetti](https://en.wikipedia.org/wiki/Bruno_de_Finetti),
[L. J. Savage](https://en.wikipedia.org/wiki/Leonard_Jimmie_Savage),
[D. V. Lindley](https://en.wikipedia.org/wiki/Dennis_Lindley),
[G. E. P. Box](https://en.wikipedia.org/wiki/George_E._P._Box),
and others between 1950 and 1980, but it remained impractical.
The handful of very simple Bayesian models that one learns to
analyze by hand in a theory course like STAT 5101â€“5102 are just
about all the Bayesian inference one can do by hand.
More are found in Box and Tiao, *Bayesian Inference in Statistical Analysis*
(Addison-Wesley, 1973, now out of print) but not much more.
Bayesian inference was revolutionized in 1990 when the connection
was made with Markov chain Monte Carlo (MCMC) which allowed Bayesianism
to be applied universally (in principle).

## The Monte Carlo Method

The [Monte Carlo
method](https://en.wikipedia.org/wiki/Monte_Carlo_method#History)
is a cute name for computer simulation of
probability distributions and calculating probabilities and expectations
by averaging over the simulations (more on this later).
At the time the term was invented gambling was illegal everywhere
in the USA but Nevada and was still a small industry there.
The casino at Monte Carlo
(in the country of Monaco) was the most famous in the world; gambling has
something to do with probability; hence the name.
It has now become a colorless technical term, used with no thought of its
original motivation.

It refers to a lot more than just simulation studies in statistics.
Any integral or sum that cannot be done analytically,
either by hand or by a [computer algebra
system](https://en.wikipedia.org/wiki/Computer_algebra_system)
can be put in the form of the expectation of some random variable
with respect to some probability distribution.  So it is a general
method of doing integrals or sums.

## MCMC

So we now turn to Markov chain Monte Carlo (MCMC).
[Markov chains](https://en.wikipedia.org/wiki/Markov_chain) were invented by
[A. A. Markov](https://en.wikipedia.org/wiki/Andrey_Markov) sometime before
1906 when his first paper on the subject was published.
They are *dependent* sequences of random variables having
the *Markov property*: past and future are conditionally independent given
the present (this may not make any sense if you do not understand conditional
probability, which will be explained below, since it is
crucial to both MCMC and Bayesian inference).  Classical physics has this
property.
If everything was known about the present state of the universe, then
[Laplace's demon](https://en.wikipedia.org/wiki/Laplace%27s_demon) could
calculate the entire future history.
Quantum physics may or may not share it, depending on one's views about
the [Heisenberg uncertainty
principle](https://en.wikipedia.org/wiki/Uncertainty_principle).
Nevertheless Markov chains were the first non-IID (not independent and
identically distributed) stochastic processes
to be characterized and have the richest theory.

MCMC was invented (not under that name, more on that later) by
[Metropolis, Rosenbluth, Rosenbluth, Teller, and Teller
(1953)](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm)
at [Los Alamos](https://en.wikipedia.org/wiki/Los_Alamos_National_Laboratory),
one of the few places in the world at the time that had the computers necessary
to do it.  The method they invented, originally known as
the *Metropolis algorithm* is an incredible *tour de force*.  They were
studying the problem of describing the equilibrium between the liquid and
gas phase of substances.  The natural approach is to write down the physics
and simulate it until the system achieves thermodynamic equilibrium and
then record what happens to the simulation.  The *tour de force* is that
many different Markov processes can have the *same equilibrium distribution*
(more on this below) so there is no need to simulate the correct physics;
one can use Markov chains that are much easier to simulate.
Markov chains use discrete time, which suits computers much better
(than continuous time used in real physics).  So Metropolis et al. invented
a totally artificial but very convenient way to simulate *any continuous
distribution of a random vector* whatsoever.

This method was later generalized by [Hastings
(1970)](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm)
and then generalized further by [Green 
(1995)](https://en.wikipedia.org/wiki/Reversible-jump_Markov_chain_Monte_Carlo).
These are known under the names *Metropolis-Hastings algorithm* (a widely
used name) and *Metropolis-Hastings-Green algorithm* (a name your humble
author is trying to popularize, [Handbook of Markov Chain Monte Carlo,
Chapter 1, Introduction](https://www.mcmchandbook.net/HandbookChapter1.pdf))
and the *reversible jump* algorithm
(so-called by Green (1995), who, of course, could not name it after himself).
[AFAIK](https://www.google.com/#q=AFAIK) every practically usable form of
MCMC is a special case of the Metropolis-Hastings-Green algorithm
(although an incredible bunch of names for various special cases are in use).

The so-called [Gibbs sampler](https://en.wikipedia.org/wiki/Gibbs_sampling)
was invented by Geman and Geman (1983).  The name is odd.  It has nothing
to do with any math done by
[Gibbs](https://en.wikipedia.org/wiki/Josiah_Willard_Gibbs) but rather
refers to the fact that it is useful for simulating thermodynamic equilibrium
distributions, which are sometimes called [Gibbs 
distributions](https://en.wikipedia.org/wiki/Boltzmann_distribution).
It is not clear at all from reading the Geman and Geman paper that they had
anything
like our current understanding of what they invented; most of their paper
is about optimization rather than sampling.  Their algorithm is also a special
case of the Metropolis-Hastings-Green algorithm and may or may not be
a special case of the Metropolis-Hastings algorithm depending on how much
credit you are willing to give Hastings for things the paper does not
explicitly state but are a straightforward extension of his methods
(Geman and Geman cite Metropolis, et al. but not Hastings).

The term MCMC may have been coined by your humble author
[Geyer (1992)](http://projecteuclid.org/euclid.ss/1177011137).
At least, the paper cited was influential in introducing the view
that Markov chains are the key concept in MCMC (which was unclear in
earlier work).  Another, even more influential, paper along these lines
was [Tierney (1994)](http://projecteuclid.org/euclid.aos/1176325750),
which, anachronistically, was an influence on Geyer (1992).  The Tierney
paper was a technical report before I started to write my paper.  It
is just that *Annals of Statistics* had a much slower publication process
than *Statistical Science*.  Also Tierney and I were in the same department
([U of M](http://www.stat.umn.edu/)) at the time and had many discussions
about MCMC.

MCMC is a very general method of simulation.  Suppose we have a computer
program (in R and pseudocode)

    for (i in 1:nsim) {
        make a (pseudo) random change to x
        output x
    }

This is a Markov chain

 * provided we consider pseudorandom numbers as if they
   were truly random (which is the whole point of using them), and

 * provided that `x` is the *whole state of the program exclusive
   of the internals of the random number generator* (that is, the
   seeds).

Pretty much any simulation has or can have (if we reconsider what we
call `x`) this structure.  Thus there are two kinds of simulations

 * those that are MCMC and this is used in their analysis, and

 * those that are MCMC but this is ignored and some hand-wave "justifies"
   their analysis.

## Bayes Meets MCMC

Geman and Geman invented the Gibbs sampler to do Bayesian inference in
[spatial statistics](https://en.wikipedia.org/wiki/Spatial_analysis).
The idea that it (and other methods of MCMC) might be useful not only
for the incredibly complicated statistical models used in spatial statistics
but also for quite simple statistical models whose Bayesian inference is
still analytically intractable, doable neither by hand nor by a
[computer algebra
system](https://en.wikipedia.org/wiki/Computer_algebra_system).
was put forward by [Gelfand and Smith
(1990)](http://www.jstor.org/stable/2289776).
This was followed by conferences (the first organized
by Gelfand and Smith) and much research by many Bayesians.

Baysian inference via MCMC was the bandwagon of the nineties in statistics.
Its usage [exploded after 1990](https://books.google.com/ngrams/graph?content=Gibbs+sampler%2CMarkov+chain+Monte+Carlo%2CMCMC&year_start=1980&year_end=2017&corpus=15&smoothing=3&share=&direct_url=t1%3B%2CGibbs%20sampler%3B%2Cc0%3B.t1%3B%2CMarkov%20chain%20Monte%20Carlo%3B%2Cc0%3B.t1%3B%2CMCMC%3B%2Cc0)
(Google Ngram is seriously distorted because it looks only at books,
not scientific papers,
but Google Trends only goes back to 2004 after the popularity had already
peaked).
Another indication is that Google Scholar says Gelfand and Smith (1990) is
"cited by 10080" (as I write this), and surely only a minority of MCMC
for Bayes papers have cited the source of the bandwagon.
So this paper was hugely influential.

